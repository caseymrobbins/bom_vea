{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# BOM-VAE vs Î²-VAE Comparison on CelebA\n",
    "\n",
    "**Hypothesis**: BOM achieves comparable or better results than Î²-VAE without requiring hyperparameter tuning.\n",
    "\n",
    "**Adaptive squeeze rule**:\n",
    "```\n",
    "squeeze_amount = (s_min - 0.5) * k\n",
    "```\n",
    "- When s_min = 0.9: squeeze aggressively\n",
    "- When s_min = 0.55: squeeze gently\n",
    "- When s_min â‰¤ 0.5: stop squeezing\n",
    "\n",
    "---\n",
    "\n",
    "## Setup Instructions\n",
    "\n",
    "1. **Select GPU Runtime**: Runtime â†’ Change runtime type â†’ **L4 GPU** (or T4/A100)\n",
    "2. **Run all cells** in order\n",
    "3. **Total runtime**: ~3-4 hours on L4, ~1.5 hours on A100\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## 1. Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install gdown -q\n",
    "\n",
    "# Check GPU\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 2. Download CelebA Dataset\n",
    "\n",
    "This will download ~1.4GB and extract ~200k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-celeba"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import gdown\n",
    "import glob\n",
    "\n",
    "celeba_path = '/content/celeba'\n",
    "zip_path = '/content/celeba.zip'\n",
    "\n",
    "# Download if not exists\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading CelebA dataset (~1.4GB)...\")\n",
    "    gdown.download(\n",
    "        \"https://drive.google.com/uc?id=1xJs_8JB0HYXiaAmU8PTG9qbk0WJ2Wo1U\",\n",
    "        zip_path,\n",
    "        quiet=False\n",
    "    )\n",
    "else:\n",
    "    print(f\"Zip already exists: {zip_path}\")\n",
    "\n",
    "# Extract if not extracted\n",
    "if not os.path.exists(celeba_path) or len(os.listdir(celeba_path)) == 0:\n",
    "    print(\"Extracting dataset...\")\n",
    "    os.makedirs(celeba_path, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        z.extractall(celeba_path)\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(f\"Already extracted: {celeba_path}\")\n",
    "\n",
    "# Verify\n",
    "num_images = len(glob.glob(f\"{celeba_path}/**/*.jpg\", recursive=True))\n",
    "print(f\"\\nâœ“ Found {num_images:,} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "code-header"
   },
   "source": [
    "## 3. Import Libraries and Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm  # Better progress bars in Colab\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vae-model"
   },
   "outputs": [],
   "source": [
    "# VAE Architecture\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.enc = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, 2, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(32, 64, 3, 2, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 3, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(128, 256, 3, 2, 1), nn.BatchNorm2d(256), nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(256*4*4, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256*4*4, latent_dim)\n",
    "        self.fc_dec = nn.Linear(latent_dim, 256*4*4)\n",
    "        self.dec = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 3, 2, 1, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(128, 64, 3, 2, 1, 1), nn.BatchNorm2d(64), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(64, 32, 3, 2, 1, 1), nn.BatchNorm2d(32), nn.LeakyReLU(0.2),\n",
    "            nn.ConvTranspose2d(32, 3, 3, 2, 1, 1), nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.enc(x).view(x.size(0), -1)\n",
    "        mu, logvar = self.fc_mu(h), self.fc_logvar(h)\n",
    "        z = mu + torch.randn_like(mu) * torch.exp(0.5 * logvar)\n",
    "        return self.dec(self.fc_dec(z).view(-1, 256, 4, 4)), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-header"
   },
   "source": [
    "## 4. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data-loader"
   },
   "outputs": [],
   "source": [
    "def load_celeba(data_path, batch_size=128, image_size=64, num_workers=4):\n",
    "    \"\"\"Load CelebA dataset.\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.CenterCrop(178),  # CelebA is 218x178\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    if os.path.basename(data_path) == 'img_align_celeba':\n",
    "        data_path = os.path.dirname(data_path)\n",
    "    \n",
    "    dataset = datasets.ImageFolder(root=data_path, transform=transform)\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Loaded CelebA: {len(dataset):,} images, {len(loader)} batches\")\n",
    "    return loader\n",
    "\n",
    "# Load data (adjust batch_size based on GPU)\n",
    "# L4: 128, A100: 256, T4: 64\n",
    "BATCH_SIZE = 128  # Adjust if needed\n",
    "train_loader = load_celeba(celeba_path, batch_size=BATCH_SIZE)\n",
    "test_loader = load_celeba(celeba_path, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "metrics-header"
   },
   "source": [
    "## 5. Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "metrics"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(x, x_recon, mu, logvar):\n",
    "    \"\"\"Compute MSE, KL, and sharpness.\"\"\"\n",
    "    B = x.size(0)\n",
    "    mse = F.mse_loss(x_recon, x, reduction='none').view(B, -1).mean(1)\n",
    "    kl = -0.5 * (1 + logvar - mu.pow(2) - logvar.exp()).sum(1)\n",
    "    dx = torch.abs(x_recon[:,:,:,1:] - x_recon[:,:,:,:-1])\n",
    "    dy = torch.abs(x_recon[:,:,1:,:] - x_recon[:,:,:-1,:])\n",
    "    sharp = (dx.mean([1,2,3]) + dy.mean([1,2,3])) / 2\n",
    "    return mse, kl, sharp\n",
    "\n",
    "def evaluate(model, loader, device, max_batches=100):\n",
    "    \"\"\"Evaluate model on test set.\"\"\"\n",
    "    model.eval()\n",
    "    all_mse, all_kl, all_sharp = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= max_batches: break\n",
    "            x = batch[0].to(device)\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            all_mse.extend(mse.cpu().numpy())\n",
    "            all_kl.extend(kl.cpu().numpy())\n",
    "            all_sharp.extend(sharp.cpu().numpy())\n",
    "    \n",
    "    return {\n",
    "        'mse': np.mean(all_mse),\n",
    "        'kl': np.mean(all_kl),\n",
    "        'sharp': np.mean(all_sharp),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beta-vae-header"
   },
   "source": [
    "## 6. Î²-VAE Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beta-vae-train"
   },
   "outputs": [],
   "source": [
    "def train_beta_vae(model, loader, device, beta, n_epochs=20):\n",
    "    \"\"\"Standard Î²-VAE training. Loss = MSE + Î² * KL\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss, epoch_mse, epoch_kl = [], [], []\n",
    "        \n",
    "        pbar = tqdm(loader, desc=f\"Î²-VAE (Î²={beta}) Epoch {epoch}/{n_epochs}\")\n",
    "        for batch in pbar:\n",
    "            x = batch[0].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            \n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            loss = mse.mean() + beta * kl.mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss.append(loss.item())\n",
    "            epoch_mse.append(mse.mean().item())\n",
    "            epoch_kl.append(kl.mean().item())\n",
    "            \n",
    "            history.append({\n",
    "                'mse': mse.mean().item(),\n",
    "                'kl': kl.mean().item(),\n",
    "                'sharp': sharp.mean().item(),\n",
    "            })\n",
    "            \n",
    "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'mse': f\"{mse.mean().item():.4f}\", 'kl': f\"{kl.mean().item():.0f}\"})\n",
    "        \n",
    "        print(f\"  Epoch {epoch}: loss={np.mean(epoch_loss):.4f}, mse={np.mean(epoch_mse):.4f}, kl={np.mean(epoch_kl):.0f}\")\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bom-vae-header"
   },
   "source": [
    "## 7. BOM-VAE Training with Adaptive Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bom-constraints"
   },
   "outputs": [],
   "source": [
    "def regular_constraint_lower_better(value, floor):\n",
    "    \"\"\"Score for objectives where lower is better (MSE).\"\"\"\n",
    "    return (floor - value) / floor\n",
    "\n",
    "def regular_constraint_higher_better(value, ceiling):\n",
    "    \"\"\"Score for objectives where higher is better (sharpness).\"\"\"\n",
    "    return value / ceiling\n",
    "\n",
    "def box_constraint(value, floor_low, optimum, floor_high):\n",
    "    \"\"\"Score for objectives that need to stay in a range (KL).\"\"\"\n",
    "    left = (value - floor_low) / (optimum - floor_low)\n",
    "    right = (floor_high - value) / (floor_high - optimum)\n",
    "    return torch.minimum(left, right)\n",
    "\n",
    "def compute_bom_loss(x, x_recon, mu, logvar, mse_floor, kl_floor_low, kl_optimum, kl_floor_high, sharp_ceiling):\n",
    "    \"\"\"Compute BOM loss.\"\"\"\n",
    "    mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "    \n",
    "    mse_score = regular_constraint_lower_better(mse, mse_floor)\n",
    "    kl_score = box_constraint(kl, kl_floor_low, kl_optimum, kl_floor_high)\n",
    "    sharp_score = regular_constraint_higher_better(sharp, sharp_ceiling)\n",
    "    \n",
    "    scores = torch.stack([mse_score, kl_score, sharp_score], dim=1)\n",
    "    s_min, min_idx = torch.min(scores, dim=1)\n",
    "    \n",
    "    violations = (s_min <= 0).sum().item()\n",
    "    \n",
    "    metrics = {\n",
    "        'mse': mse.mean().item(),\n",
    "        'kl': kl.mean().item(),\n",
    "        'sharp': sharp.mean().item(),\n",
    "        'mse_score': mse_score.mean().item(),\n",
    "        'kl_score': kl_score.mean().item(),\n",
    "        'sharp_score': sharp_score.mean().item(),\n",
    "        's_min': s_min.mean().item(),\n",
    "        'violations': violations,\n",
    "    }\n",
    "    \n",
    "    if violations > 0:\n",
    "        return None, metrics\n",
    "    \n",
    "    loss = -torch.log(s_min).mean()\n",
    "    names = ['mse', 'kl', 'sharp']\n",
    "    metrics['bottleneck'] = names[torch.bincount(min_idx, minlength=3).argmax().item()]\n",
    "    metrics['loss'] = loss.item()\n",
    "    \n",
    "    return loss, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bom-calibrate"
   },
   "outputs": [],
   "source": [
    "def calibrate_bom(model, loader, device, n_batches=50):\n",
    "    \"\"\"Calibrate BOM constraints based on model's current outputs.\"\"\"\n",
    "    model.train()\n",
    "    all_mse, all_kl, all_sharp = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= n_batches: break\n",
    "            x = batch[0].to(device)\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            mse, kl, sharp = compute_metrics(x, x_recon, mu, logvar)\n",
    "            all_mse.extend(mse.cpu().numpy())\n",
    "            all_kl.extend(kl.cpu().numpy())\n",
    "            all_sharp.extend(sharp.cpu().numpy())\n",
    "    \n",
    "    mse_arr = np.array(all_mse)\n",
    "    kl_arr = np.array(all_kl)\n",
    "    sharp_arr = np.array(all_sharp)\n",
    "    \n",
    "    params = {\n",
    "        'mse_floor': mse_arr.max() * 2.0,\n",
    "        'kl_floor_low': kl_arr.min() * 0.1,\n",
    "        'kl_optimum': kl_arr.mean(),\n",
    "        'kl_floor_high': kl_arr.max() * 50.0,\n",
    "        'sharp_ceiling': sharp_arr.mean(),\n",
    "    }\n",
    "    \n",
    "    print(f\"Calibration: MSE={mse_arr.mean():.4f}, KL={kl_arr.mean():.1f}, Sharp={sharp_arr.mean():.4f}\")\n",
    "    print(f\"Initial constraints: mse_floor={params['mse_floor']:.4f}, kl_box=[{params['kl_floor_low']:.1f}, {params['kl_optimum']:.1f}, {params['kl_floor_high']:.1f}]\")\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bom-train"
   },
   "outputs": [],
   "source": [
    "def train_bom_vae(model, loader, device, n_epochs=20):\n",
    "    \"\"\"BOM-VAE training with adaptive squeeze.\"\"\"\n",
    "    # Calibrate\n",
    "    params = calibrate_bom(model, loader, device)\n",
    "    \n",
    "    mse_floor = params['mse_floor']\n",
    "    kl_floor_low = params['kl_floor_low']\n",
    "    kl_optimum = params['kl_optimum']\n",
    "    kl_floor_high = params['kl_floor_high']\n",
    "    sharp_ceiling = params['sharp_ceiling']\n",
    "    \n",
    "    # Targets\n",
    "    target_kl_floor_low = 50\n",
    "    target_kl_optimum = 80\n",
    "    target_kl_floor_high = 150\n",
    "    \n",
    "    # Adaptive squeeze settings\n",
    "    squeeze_k = 0.5\n",
    "    min_s_min_for_squeeze = 0.5\n",
    "    squeeze_start_epoch = 3\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        epoch_loss, epoch_s_min = [], []\n",
    "        epoch_violations = 0\n",
    "        \n",
    "        pbar = tqdm(loader, desc=f\"BOM-VAE Epoch {epoch}/{n_epochs}\")\n",
    "        for batch in pbar:\n",
    "            x = batch[0].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            x_recon, mu, logvar = model(x)\n",
    "            \n",
    "            loss, metrics = compute_bom_loss(\n",
    "                x, x_recon, mu, logvar,\n",
    "                mse_floor, kl_floor_low, kl_optimum, kl_floor_high, sharp_ceiling\n",
    "            )\n",
    "            \n",
    "            if loss is not None:\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                optimizer.step()\n",
    "                epoch_loss.append(metrics['loss'])\n",
    "                epoch_s_min.append(metrics['s_min'])\n",
    "            else:\n",
    "                epoch_violations += metrics['violations']\n",
    "            \n",
    "            history.append(metrics)\n",
    "            pbar.set_postfix({'s_min': f\"{metrics['s_min']:.3f}\", 'kl': f\"{metrics['kl']:.0f}\"})\n",
    "        \n",
    "        avg_s_min = np.mean(epoch_s_min) if epoch_s_min else 0\n",
    "        print(f\"  Epoch {epoch}: s_min={avg_s_min:.3f}, violations={epoch_violations}, mse={metrics['mse']:.4f}, kl={metrics['kl']:.0f}\")\n",
    "        print(f\"    KL box: [{kl_floor_low:.1f}, {kl_optimum:.1f}, {kl_floor_high:.1f}]\")\n",
    "        \n",
    "        # Adaptive squeeze\n",
    "        if epoch >= squeeze_start_epoch and avg_s_min > min_s_min_for_squeeze:\n",
    "            squeeze_amount = (avg_s_min - min_s_min_for_squeeze) * squeeze_k\n",
    "            squeeze_factor = 1.0 - squeeze_amount\n",
    "            squeeze_factor = max(0.5, squeeze_factor)\n",
    "            \n",
    "            print(f\"    ðŸ”§ Squeeze: s_min={avg_s_min:.3f} -> factor={squeeze_factor:.2f}\")\n",
    "            \n",
    "            mse_floor *= squeeze_factor\n",
    "            \n",
    "            if kl_floor_low < target_kl_floor_low:\n",
    "                kl_floor_low += (target_kl_floor_low - kl_floor_low) * (1 - squeeze_factor)\n",
    "            if kl_optimum < target_kl_optimum:\n",
    "                kl_optimum += (target_kl_optimum - kl_optimum) * (1 - squeeze_factor)\n",
    "            if kl_floor_high > target_kl_floor_high:\n",
    "                kl_floor_high -= (kl_floor_high - target_kl_floor_high) * (1 - squeeze_factor)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-header"
   },
   "source": [
    "## 8. Run Comparison\n",
    "\n",
    "**Training time estimate:**\n",
    "- L4 (24GB): ~3-4 hours\n",
    "- A100 (40GB): ~1.5 hours\n",
    "- T4 (16GB): ~5-6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-comparison"
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 20  # Reduce to 5 for quick test\n",
    "results = {}\n",
    "\n",
    "# Î²-VAE with different Î² values\n",
    "betas = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "for beta in betas:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training Î²-VAE with Î²={beta}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    model = VAE(latent_dim=128).to(device)\n",
    "    history = train_beta_vae(model, train_loader, device, beta=beta, n_epochs=N_EPOCHS)\n",
    "    test_metrics = evaluate(model, test_loader, device, max_batches=100)\n",
    "    \n",
    "    results[f'beta_{beta}'] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'test': test_metrics,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTest results: MSE={test_metrics['mse']:.4f}, KL={test_metrics['kl']:.1f}, Sharp={test_metrics['sharp']:.4f}\")\n",
    "\n",
    "# BOM-VAE\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training BOM-VAE (no Î² tuning required)\")\n",
    "print('='*60)\n",
    "\n",
    "model_bom = VAE(latent_dim=128).to(device)\n",
    "history_bom = train_bom_vae(model_bom, train_loader, device, n_epochs=N_EPOCHS)\n",
    "test_metrics_bom = evaluate(model_bom, test_loader, device, max_batches=100)\n",
    "\n",
    "results['bom'] = {\n",
    "    'model': model_bom,\n",
    "    'history': history_bom,\n",
    "    'test': test_metrics_bom,\n",
    "}\n",
    "\n",
    "print(f\"\\nTest results: MSE={test_metrics_bom['mse']:.4f}, KL={test_metrics_bom['kl']:.1f}, Sharp={test_metrics_bom['sharp']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results-header"
   },
   "source": [
    "## 9. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results-summary"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Method':<20} {'MSE':>10} {'KL':>10} {'Sharpness':>12}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for name, data in results.items():\n",
    "    t = data['test']\n",
    "    print(f\"{name:<20} {t['mse']:>10.4f} {t['kl']:>10.1f} {t['sharp']:>12.4f}\")\n",
    "\n",
    "print(\"-\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viz-header"
   },
   "source": [
    "## 10. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-training-curves"
   },
   "outputs": [],
   "source": [
    "# Training curves comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for name, data in results.items():\n",
    "    h = data['history']\n",
    "    label = name.replace('_', '=')\n",
    "    \n",
    "    axes[0].plot([x['mse'] for x in h], label=label, alpha=0.8)\n",
    "    axes[1].plot([x['kl'] for x in h], label=label, alpha=0.8)\n",
    "    axes[2].plot([x['sharp'] for x in h], label=label, alpha=0.8)\n",
    "\n",
    "axes[0].set_title('MSE (â†“ better)')\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].set_title('KL Divergence')\n",
    "axes[1].set_xlabel('Step')\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].set_title('Sharpness (â†‘ better)')\n",
    "axes[2].set_xlabel('Step')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/training_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-pareto"
   },
   "outputs": [],
   "source": [
    "# Pareto plot: MSE vs KL\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(results)))\n",
    "\n",
    "for (name, data), color in zip(results.items(), colors):\n",
    "    t = data['test']\n",
    "    marker = 's' if 'beta' in name else 'o'\n",
    "    size = 100 if 'bom' in name else 60\n",
    "    plt.scatter(t['mse'], t['kl'], s=size, c=[color], marker=marker, \n",
    "                label=name.replace('_', '='), edgecolors='black')\n",
    "\n",
    "plt.xlabel('MSE (â†“ better)')\n",
    "plt.ylabel('KL (moderate is better)')\n",
    "plt.title('Pareto Front: MSE vs KL')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('/content/pareto_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-reconstructions"
   },
   "outputs": [],
   "source": [
    "# Reconstructions comparison\n",
    "test_batch = next(iter(test_loader))[0][:8].to(device)\n",
    "\n",
    "n_models = len(results)\n",
    "fig, axes = plt.subplots(n_models + 1, 8, figsize=(16, 2*(n_models+1)))\n",
    "\n",
    "# Original\n",
    "for i in range(8):\n",
    "    axes[0, i].imshow(test_batch[i].cpu().permute(1,2,0))\n",
    "    axes[0, i].axis('off')\n",
    "axes[0, 0].set_ylabel('Original', fontsize=12)\n",
    "\n",
    "# Each model's reconstruction\n",
    "for row, (name, data) in enumerate(results.items(), 1):\n",
    "    model = data['model']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        recon, _, _ = model(test_batch)\n",
    "    \n",
    "    for i in range(8):\n",
    "        axes[row, i].imshow(recon[i].cpu().permute(1,2,0))\n",
    "        axes[row, i].axis('off')\n",
    "    axes[row, 0].set_ylabel(name.replace('_', '='), fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/reconstructions_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz-samples"
   },
   "outputs": [],
   "source": [
    "# Samples from prior comparison\n",
    "z = torch.randn(8, 128, device=device)\n",
    "\n",
    "n_models = len(results)\n",
    "fig, axes = plt.subplots(n_models, 8, figsize=(16, 2*n_models))\n",
    "\n",
    "for row, (name, data) in enumerate(results.items()):\n",
    "    model = data['model']\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        samples = model.dec(model.fc_dec(z).view(-1, 256, 4, 4))\n",
    "    \n",
    "    for i in range(8):\n",
    "        axes[row, i].imshow(samples[i].cpu().permute(1,2,0))\n",
    "        axes[row, i].axis('off')\n",
    "    axes[row, 0].set_ylabel(name.replace('_', '='), fontsize=12)\n",
    "\n",
    "plt.suptitle('Samples from Prior (same z for all models)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/content/samples_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-header"
   },
   "source": [
    "## 11. Download Results\n",
    "\n",
    "All plots are saved in `/content/`. You can download them from the Files panel on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-results"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download all plots\n",
    "files.download('/content/training_comparison.png')\n",
    "files.download('/content/pareto_comparison.png')\n",
    "files.download('/content/reconstructions_comparison.png')\n",
    "files.download('/content/samples_comparison.png')\n",
    "\n",
    "print(\"âœ“ All plots downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusion-header"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Î²-VAE** requires tuning Î² to balance reconstruction vs regularization\n",
    "   - Different Î² values give different tradeoffs\n",
    "   - Low Î² (0.0001): Good MSE, but KL may collapse\n",
    "   - High Î² (0.1): Controlled KL, but poor reconstruction\n",
    "\n",
    "2. **BOM-VAE** automatically finds a balanced solution\n",
    "   - No Î² hyperparameter to tune\n",
    "   - Adaptive squeeze finds the Pareto frontier\n",
    "   - All objectives are explicitly constrained\n",
    "\n",
    "3. **The key insight**: BOM optimizes the WORST objective at each step, preventing any single objective from being sacrificed.\n",
    "\n",
    "---\n",
    "\n",
    "**Next Steps:**\n",
    "- Compare visual quality in reconstructions\n",
    "- Check which Î²-VAE performs best\n",
    "- See if BOM-VAE matches or exceeds best Î²-VAE\n",
    "- Analyze latent space quality (optional: add classifier test)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
