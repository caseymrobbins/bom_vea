{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOM VAE v15 - LBO Compliant Training\n",
    "\n",
    "**Features:**\n",
    "- Pure LBO with Directive #4 rollback mechanism\n",
    "- Directive #6: Adaptive squeeze starting at plateau (epochs 5, 8, 11, 14, 17)\n",
    "- Behavioral disentanglement testing (core→structure, detail→appearance)\n",
    "- 35 epochs, L4 GPU optimized (batch_size=256)\n",
    "- NO epsilon, NO softmin, NO clamps on goals - pure `-log(min())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and checkout branch\n",
    "!git clone https://github.com/caseymrobbins/bom_vea.git\n",
    "%cd bom_vea\n",
    "!git checkout claude/loss-function-goals-kRaQb\n",
    "!git log -1 --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision tqdm pillow scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and setup CelebA dataset\n",
    "!python celeba_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Current settings:\n",
    "- **Epochs**: 35\n",
    "- **Batch Size**: 256 (L4 GPU)\n",
    "- **Learning Rate**: 1e-3 (VAE), 1e-4 (Discriminator)\n",
    "- **Latent Dim**: 128 (16 core, 112 detail)\n",
    "- **Progressive Tightening**: Epochs 5, 8, 11, 14, 17 (starts at plateau)\n",
    "- **Stable Convergence**: Epochs 18-35 (18 epochs for final refinement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Behavior\n",
    "\n",
    "### LBO Rollback Mechanism\n",
    "If you see `[ROLLBACK]` messages, this is **expected and correct**:\n",
    "- Optimizer attempted a step that would violate constraints (S_min ≤ 0)\n",
    "- System detected violation before crash\n",
    "- State restored, update rejected\n",
    "- Training continues safely\n",
    "\n",
    "### Bottleneck Tracking\n",
    "Watch the bottleneck percentages:\n",
    "- **Epochs 1-4**: Initial convergence, recon usually dominates (60-80%)\n",
    "- **Epoch 5**: Recon tightened → should be bottleneck 85%+\n",
    "- **Epochs 6-7**: System adapts to new recon baseline\n",
    "- **Epoch 8**: Core tightened → Core/Recon compete\n",
    "- **Epochs 9-10**: Adaptation\n",
    "- **Epoch 11**: Swap tightened\n",
    "- **Epoch 14**: Realism tightened\n",
    "- **Epoch 17**: Disentangle tightened (final squeeze)\n",
    "- **Epochs 18-35**: Long stable convergence, all groups balanced\n",
    "\n",
    "### Key Metrics\n",
    "- **Loss**: Should decrease (negative log, so lower is better)\n",
    "- **Min Group**: Should increase toward 1.0 (all constraints satisfied)\n",
    "- **SSIM**: Should increase toward 1.0 (perfect reconstruction)\n",
    "- **KL**: Should stabilize within clamps [0, 10]/dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View outputs\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "output_dir = '/content/outputs_bom_v15'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    print(\"\\n=== Reconstructions ===\")\n",
    "    if os.path.exists(f'{output_dir}/reconstructions.png'):\n",
    "        display(Image(filename=f'{output_dir}/reconstructions.png'))\n",
    "    \n",
    "    print(\"\\n=== Core Traversals (Structure) ===\")\n",
    "    if os.path.exists(f'{output_dir}/traversals_core.png'):\n",
    "        display(Image(filename=f'{output_dir}/traversals_core.png'))\n",
    "    \n",
    "    print(\"\\n=== Detail Traversals (Appearance) ===\")\n",
    "    if os.path.exists(f'{output_dir}/traversals_detail.png'):\n",
    "        display(Image(filename=f'{output_dir}/traversals_detail.png'))\n",
    "    \n",
    "    print(\"\\n=== Cross Reconstruction (Core/Detail Swap) ===\")\n",
    "    if os.path.exists(f'{output_dir}/cross_reconstruction.png'):\n",
    "        display(Image(filename=f'{output_dir}/cross_reconstruction.png'))\n",
    "    \n",
    "    print(\"\\n=== Group Balance Over Time ===\")\n",
    "    if os.path.exists(f'{output_dir}/group_balance.png'):\n",
    "        display(Image(filename=f'{output_dir}/group_balance.png'))\n",
    "else:\n",
    "    print(f\"Output directory not found: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Training crashes immediately\n",
    "- Check if S_min ≤ 0 violation is being caught\n",
    "- Look for `[ROLLBACK]` messages\n",
    "- If crashing with `log(0)`, the pre-log check may have a bug\n",
    "\n",
    "### Too many rollbacks (>50% of batches)\n",
    "- Learning rate may be too high\n",
    "- Consider reducing LR: 1e-3 → 5e-4\n",
    "- Or widen initial BOX constraints\n",
    "\n",
    "### OOM (Out of Memory)\n",
    "- Reduce batch size: 256 → 128\n",
    "- L4 has 24GB, should handle 256 fine\n",
    "- If using A100, can increase to 512\n",
    "\n",
    "### Disentangle always at 1.0\n",
    "- Expected at init (collapsed encoder)\n",
    "- Should drop as latent space becomes expressive\n",
    "- If still 1.0 at epoch 20+, encoder may not be learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
