{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOM VAE v15 - LBO Compliant Training\n",
    "\n",
    "**Features:**\n",
    "- Pure LBO with Directive #4 rollback mechanism\n",
    "- Directive #6: Natural adaptive squeeze (LBO's infinite gradient automatically pushes all groups ‚Üí 1.0)\n",
    "- Behavioral disentanglement testing (core‚Üístructure, detail‚Üíappearance)\n",
    "- 35 epochs, L4 GPU optimized (batch_size=256)\n",
    "- NO epsilon, NO softmin, NO clamps on goals - pure `-log(min())`\n",
    "- NO manual recalibration - scales set once at epoch 1, then natural improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and checkout branch\n",
    "!git clone https://github.com/caseymrobbins/bom_vea.git\n",
    "%cd bom_vea\n",
    "!git checkout claude/loss-function-goals-kRaQb\n",
    "!git log -1 --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q torch torchvision tqdm pillow scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and setup CelebA dataset\n",
    "!python celeba_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Training Configuration\n\nCurrent settings:\n- **Epochs**: 35 (max - may stop early)\n- **Batch Size**: 256 (L4 GPU)\n- **Learning Rate**: 1e-3 (VAE), 1e-4 (Discriminator)\n- **Latent Dim**: 128 (16 core, 112 detail)\n- **Calibration**: Epoch 1 only (sets initial scales)\n- **Adaptive Tightening**: Starts epoch 5, tightens 5%/epoch until rollback rate hits 5%, then 1 more epoch and stops"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Expected Behavior\n\n### LBO Rollback Mechanism\nIf you see `[ROLLBACK]` messages, this is **expected and correct**:\n- Optimizer attempted a step that would violate constraints (S_min ‚â§ 0)\n- System detected violation before crash\n- State restored, update rejected\n- Training continues safely\n\n### Adaptive Tightening & Early Stopping (LBO Directive #6)\nThe system automatically tightens constraints and stops when optimal:\n- **Epochs 1-4**: Initial calibration and convergence\n- **Epochs 5+**: Automatic tightening begins (5% per epoch)\n  - Tightens MINIMIZE_SOFT scales ‚Üí goals harder to achieve\n  - Narrows BOX bounds ‚Üí stricter constraints\n- **At 5% rollback rate**: Constraints are optimally tight\n  - System runs 1 more epoch for stability\n  - Training stops automatically (may be before epoch 35)\n- **üèÅ STOPPING message**: Indicates successful convergence\n\n### How Adaptive Tightening Works\n1. **Monitor rollback rate**: `rollbacks / total_batches`\n2. **While rate < 5%**: Tighten all constraints by 5%\n3. **When rate ‚â• 5%**: Stop tightening (constraints at limit)\n4. **After 1 more epoch**: Stop training (optimal convergence reached)\n\nThis ensures training stops exactly when constraints are maximally tight without excessive rejections.\n\n### Bottleneck Tracking\nWatch the bottleneck percentages - they should shift naturally:\n- Early: Recon typically dominates (hardest to perfect)\n- Mid: Competition between recon, core, realism\n- Late: More balanced as all groups approach 1.0\n\n### Key Metrics\n- **Loss**: Should decrease steadily (negative log, so lower is better)\n- **Min Group**: Should increase toward 1.0 (all constraints satisfied)\n- **SSIM**: Should increase toward 1.0 (perfect reconstruction)\n- **KL**: Should stabilize within clamps [0, 10]/dim\n- **Rollback Rate**: Should gradually increase as constraints tighten, stopping at ~5%"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View outputs\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "output_dir = '/content/outputs_bom_v15'\n",
    "\n",
    "if os.path.exists(output_dir):\n",
    "    print(\"\\n=== Reconstructions ===\")\n",
    "    if os.path.exists(f'{output_dir}/reconstructions.png'):\n",
    "        display(Image(filename=f'{output_dir}/reconstructions.png'))\n",
    "    \n",
    "    print(\"\\n=== Core Traversals (Structure) ===\")\n",
    "    if os.path.exists(f'{output_dir}/traversals_core.png'):\n",
    "        display(Image(filename=f'{output_dir}/traversals_core.png'))\n",
    "    \n",
    "    print(\"\\n=== Detail Traversals (Appearance) ===\")\n",
    "    if os.path.exists(f'{output_dir}/traversals_detail.png'):\n",
    "        display(Image(filename=f'{output_dir}/traversals_detail.png'))\n",
    "    \n",
    "    print(\"\\n=== Cross Reconstruction (Core/Detail Swap) ===\")\n",
    "    if os.path.exists(f'{output_dir}/cross_reconstruction.png'):\n",
    "        display(Image(filename=f'{output_dir}/cross_reconstruction.png'))\n",
    "    \n",
    "    print(\"\\n=== Group Balance Over Time ===\")\n",
    "    if os.path.exists(f'{output_dir}/group_balance.png'):\n",
    "        display(Image(filename=f'{output_dir}/group_balance.png'))\n",
    "else:\n",
    "    print(f\"Output directory not found: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Training crashes immediately\n",
    "- Check if S_min ‚â§ 0 violation is being caught\n",
    "- Look for `[ROLLBACK]` messages\n",
    "- If crashing with `log(0)`, the pre-log check may have a bug\n",
    "\n",
    "### Too many rollbacks (>50% of batches)\n",
    "- Learning rate may be too high\n",
    "- Consider reducing LR: 1e-3 ‚Üí 5e-4\n",
    "- Or widen initial BOX constraints\n",
    "\n",
    "### Groups not improving\n",
    "- Check if bottleneck shifts between groups (healthy sign)\n",
    "- Loss should decrease even if some groups plateau temporarily\n",
    "- Natural squeeze can be slower than manual tightening but more stable\n",
    "\n",
    "### OOM (Out of Memory)\n",
    "- Reduce batch size: 256 ‚Üí 128\n",
    "- L4 has 24GB, should handle 256 fine\n",
    "- If using A100, can increase to 512\n",
    "\n",
    "### Disentangle always at 1.0\n",
    "- Expected at init (collapsed encoder)\n",
    "- Should drop as latent space becomes expressive\n",
    "- If still 1.0 at epoch 20+, encoder may not be learning"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}